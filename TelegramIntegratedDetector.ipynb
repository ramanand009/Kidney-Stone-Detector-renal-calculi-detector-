{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "yCXQkrqtEc-0",
        "outputId": "f09f58ad-7b7a-4af6-f1be-c8cdea52a952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: telebot in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.10/dist-packages (from telebot) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from telebot) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (2023.7.22)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement some_module (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for some_module\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-124ef3f9f81a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtelebot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTeleBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBOT_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"question-answering\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcategorize_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install telebot\n",
        "import telebot\n",
        "import shutil\n",
        "\n",
        "\n",
        "import os\n",
        "import telebot\n",
        "from telebot import types\n",
        "BOT_TOKEN = '6568653907:AAElgwsasILjTUDDZKoOJFeSBbqEqB3xW6s'\n",
        "\n",
        "\n",
        "\n",
        "bot = telebot.TeleBot(BOT_TOKEN)\n",
        "nlp_model = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "def categorize_prediction(probability):\n",
        "    if probability < 0.3:\n",
        "        return \"low\"\n",
        "    elif 0.3 <= probability < 0.7:\n",
        "        return \"moderate\"\n",
        "    else:\n",
        "        return \"high\"\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def echo_photo(message):\n",
        "    # Get the photo ID of the largest available photo\n",
        "    photo = message.photo[-1]\n",
        "\n",
        "    # Download the photo\n",
        "    photo_info = bot.get_file(photo.file_id)\n",
        "    photo_url = f\"https://api.telegram.org/file/bot{BOT_TOKEN}/{photo_info.file_path}\"\n",
        "\n",
        "    # Define the folder where images will be saved\n",
        "    save_folder = \"saved_images\"\n",
        "    try:\n",
        "        shutil.rmtree(\"/content/saved_images\")\n",
        "        shutil.rmtree(\"/content/runs/detect/predict\")\n",
        "\n",
        "        #print(f\"Directory '{directory_path}' and its contents have been removed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error while removing directory: {e}\")\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # Define the image filename\n",
        "    image_filename = f\"{message.from_user.id}_{message.message_id}.jpg\"\n",
        "    image_path = os.path.join(save_folder, image_filename)\n",
        "\n",
        "    os.system(f\"wget -O {image_path} {photo_url}\")\n",
        "    !yolo task=detect mode=predict model=/content/drive/MyDrive/cancer.pt conf=0.25 source='/content/saved_images' save=True\n",
        "    # Send the downloaded photo back to the user\n",
        "    final_image_path = os.path.join(\"/content/runs/detect/predict/\", image_filename)\n",
        "\n",
        "    with open(final_image_path, 'rb') as photo_file:\n",
        "        print(image_path)\n",
        "        bot.send_photo(message.chat.id, photo_file)\n",
        "\n",
        "    bot.reply_to(message, \"Image saved and sent!\")\n",
        "     # Extract text from the processed image using OCR\n",
        "    text = pytesseract.image_to_string(final_image_path)\n",
        "    prediction_lines = text.split('\\n')\n",
        "    responses = []\n",
        "    for prediction_text in prediction_lines:\n",
        "         if prediction_text.strip():\n",
        "            result = nlp_model(question=\"What is this prediction?\", context=prediction_text)\n",
        "\n",
        "            # Extract the predicted answer and probability for this prediction\n",
        "            predicted_answer = result['answer']\n",
        "            prediction_probability = result['score']\n",
        "\n",
        "            # Categorize the prediction based on probability using your categorize_prediction function\n",
        "            prediction_category = categorize_prediction(prediction_probability)\n",
        "\n",
        "            # Define a response\n",
        "            response = f\"Prediction: {prediction_text}\\nNLP Answer: {predicted_answer}\\nPrediction Category: {prediction_category}\"\n",
        "            responses.append(response)\n",
        "     # Send the responses for each prediction\n",
        "    for response in responses:\n",
        "        bot.send_message(message.chat.id, response)\n",
        "    # Send the downloaded photo back to the user\n",
        "    with open(final_image_path, 'rb') as photo_file:\n",
        "        bot.send_photo(message.chat.id, photo_file)\n",
        "\n",
        "    # Send the NLP response to the user\n",
        "    bot.reply_to(message, response)\n",
        "\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def handle_text_messages(message):\n",
        "    bot.reply_to(message, \"Please send an image.\")\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    bot.polling(none_stop=True)"
      ]
    }
  ]
}